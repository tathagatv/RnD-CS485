{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import scipy\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "from torchsummary import summary\n",
    "from PIL import Image\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------\n",
    "# the network\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=1, out_channels=1, init_features=24):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.encoder2 = UNet._block(features, features, name=\"enc2\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.encoder3 = UNet._block(features, features, name=\"enc3\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.encoder4 = UNet._block(features, features, name=\"enc4\")\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "\n",
    "        self.bottleneck = UNet._block(features, features, name=\"bottleneck\")\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(\n",
    "            features, features, kernel_size=2, stride=1\n",
    "        )\n",
    "        self.decoder4 = UNet._block(features*2, features, name=\"dec4\")\n",
    "        self.upconv3 = nn.ConvTranspose2d(\n",
    "            features, features, kernel_size=2, stride=1\n",
    "        )\n",
    "        self.decoder3 = UNet._block(features*2, features, name=\"dec3\")\n",
    "        self.upconv2 = nn.ConvTranspose2d(\n",
    "            features, features, kernel_size=2, stride=1\n",
    "        )\n",
    "        self.decoder2 = UNet._block(features*2, features, name=\"dec2\")\n",
    "        self.upconv1 = nn.ConvTranspose2d(\n",
    "            features, features, kernel_size=2, stride=1\n",
    "        )\n",
    "        self.decoder1 = UNet._block(features*2, features, name=\"dec1\")\n",
    "\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=features, out_channels=out_channels, kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        return self.conv(dec1)\n",
    "        # return torch.sigmoid(self.conv(dec1))\n",
    "\n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (\n",
    "                        name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (\n",
    "                        name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from ../mri-pkl/ixi_train.pkl\n",
      "Loading dataset from ../mri-pkl/ixi_valid.pkl\n",
      "data loading done\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------\n",
    "# Dataset loader\n",
    "\n",
    "def load_dataset(fn, num_images=None, shuffle=False):\n",
    "    # datadir = submit.get_path_from_template(config_mri.data_dir)\n",
    "    datadir = '../mri-pkl'\n",
    "    if fn.lower().endswith('.pkl'):\n",
    "        abspath = os.path.join(datadir, fn)\n",
    "        print ('Loading dataset from', abspath)\n",
    "        img, spec = util.load_pkl(abspath)\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "    if shuffle:\n",
    "        perm = np.arange(img.shape[0])\n",
    "        np.random.shuffle(perm)\n",
    "        if num_images is not None:\n",
    "            perm = perm[:num_images]\n",
    "        img = img[perm]\n",
    "        spec = spec[perm]\n",
    "\n",
    "    if num_images is not None:\n",
    "        img = img[:num_images]\n",
    "        spec = spec[:num_images]\n",
    "\n",
    "    # Remove last row/column of the images, we're officially 255x255 now.\n",
    "    img = img[:, :-1, :-1]\n",
    "\n",
    "    # Convert to float32.\n",
    "    assert img.dtype == np.uint8\n",
    "    img = img.astype(np.float32) / 255.0 - 0.5\n",
    "\n",
    "    return img, spec\n",
    "\n",
    "dataset_train, dataset_test = dict(), dict()\n",
    "train_img, train_spec = load_dataset('ixi_train.pkl')\n",
    "test_img, test_spec = load_dataset('ixi_valid.pkl')\n",
    "\n",
    "train_X, train_Y = np.zeros(train_img.shape), np.zeros(train_img.shape)\n",
    "test_X, test_Y = np.zeros(test_img.shape), np.zeros(test_img.shape)\n",
    "noise_std = 0.5\n",
    "for i in range(train_img.shape[0]):\n",
    "    img = train_img[i]\n",
    "    noise_X = np.random.normal(0, noise_std, img.shape)\n",
    "    noise_Y = np.random.normal(0, noise_std, img.shape)\n",
    "    train_X[i] = (img + noise_X)\n",
    "    train_Y[i] = (img + noise_Y)\n",
    "\n",
    "for i in range(test_img.shape[0]):\n",
    "    img = test_img[i]\n",
    "    noise_X = np.random.normal(0, noise_std, img.shape)\n",
    "    noise_Y = np.random.normal(0, noise_std, img.shape)\n",
    "    test_X[i] = (img + noise_X)\n",
    "    test_Y[i] = (img + noise_Y)\n",
    "\n",
    "\n",
    "print('data loading done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:3 3\n",
      "epoch 0 loss = 0.013\n",
      "epoch 1 loss = 0.002\n",
      "epoch 2 loss = 0.002\n",
      "epoch 3 loss = 0.002\n",
      "epoch 4 loss = 0.002\n",
      "epoch 5 loss = 0.002\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "model = UNet(init_features=24)\n",
    "epochs = 6\n",
    "batch_size = 4\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.02)\n",
    "\n",
    "device = torch.device(\"cuda:3\")\n",
    "torch.cuda.set_device(device)\n",
    "print(device, torch.cuda.current_device())\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "for ep in range(epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    i = 0\n",
    "    while i < len(train_X):\n",
    "\n",
    "        inputs = train_X[i : i+batch_size]\n",
    "        inputs = inputs[:, np.newaxis, :, :].astype(np.float32)\n",
    "        inputs = torch.from_numpy(inputs)\n",
    "        labels = train_img[i : i+batch_size]\n",
    "        labels = labels[:, np.newaxis, :, :].astype(np.float32)\n",
    "        labels = torch.from_numpy(labels)\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()*len(inputs)\n",
    "        i += batch_size\n",
    "        # print(\"ep %s batch %s loss %.3f\" % (ep, i//batch_size, running_loss/i))\n",
    "\n",
    "    running_loss = running_loss / len(train_X)\n",
    "    \n",
    "    print(\"epoch %s loss = %.3f\" % (ep, running_loss))\n",
    "\n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images created\n"
     ]
    }
   ],
   "source": [
    "img = Image.fromarray((train_img[2]+0.5)*255)\n",
    "img = img.convert('L')\n",
    "img.save('sample_clean.png')\n",
    "img = Image.fromarray((train_X[2]+0.5)*255)\n",
    "img = img.convert('L')\n",
    "img.save('sample_X.png')\n",
    "img_arr = train_X[2][np.newaxis, np.newaxis, :, :].astype(np.float32)\n",
    "img_arr = torch.from_numpy(img_arr)\n",
    "img_arr = img_arr.to(device)\n",
    "img_arr = model(img_arr).cpu().detach().numpy()\n",
    "img_arr = (img_arr[0,0] + 0.5)*255\n",
    "img = Image.fromarray(img_arr)\n",
    "img = img.convert('L')\n",
    "img.save('sample_pred.png')\n",
    "print(\"images created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.14855489683198\n",
      "54.15161646282637\n"
     ]
    }
   ],
   "source": [
    "psnr = 10*np.log10(255.0*255.0/np.square(img_arr-train_img[2]).mean())\n",
    "print(psnr)\n",
    "psnr = 10*np.log10(255.0*255.0/np.square(train_X[2]-train_img[2]).mean())\n",
    "print(psnr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
